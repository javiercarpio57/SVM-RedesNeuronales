  ---
title: "Modelo de Support Vector Machin & Redes neuronales"
author: "Javier Carpio & Paul Belches"
date: "13/04/2020"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r, include=FALSE}
#Sys.setenv(~/usr/lib/jvm/java-11-openjdk-amd64/jre)
#install.packages("rJava")
#install.packages("RWeka")
```

```{r, include=FALSE}
library(caret)
#library(dummy)
library(caret)
library(nnet)
#library(RWeka)
library(neural)
library(dummy)
library(neuralnet)
library(dplyr)
library(corrplot)
library(dplyr)
library(plyr)
library(e1071)
library(rpart)
library("rpart.plot")
library(knitr)
```

Para empezar con el análisis de los siguientes algoritmos: 

    * Árboles de decisión
    * Random Forest
    * Naive Bayes
    * Regresión Lineal
    * Regresión Logística
    * Redes Neuronales
    * Support Vector Machine
  
Debemos cargar el dataset llamado "train.csv", y para este dataset se tomarán las siguientes variables:

    * TotalBsmtSF
    * X1stFlrSF
    * GrLivArea
    * GarageCars
    * GarageArea
    * SalePrice
  
Pues como se ve en el gráfico de correlación podemos ver que tienen alta correlación con el SalePrice, que es la variable respuesta para este análisis. 
```{r}
houses <- read.csv("train.csv")
set.seed(123)

datos <-select(houses, TotalBsmtSF, X1stFlrSF, GrLivArea, GarageCars, GarageArea, SalePrice)
datos <- na.omit(datos)
matriz_cor <- cor(datos)
corrplot(matriz_cor)
```

### TotalBsmtSF

Los datos están ligeramente normalizados.
```{r}
hist(datos$TotalBsmtSF)
qqnorm(datos$TotalBsmtSF)
qqline(datos$TotalBsmtSF, col='red')

plot(datos$TotalBsmtSF, datos$SalePrice)
```

### X1stFlrSF

Los datos están ligeramente normalizados.
```{r}
hist(datos$X1stFlrSF)
qqnorm(datos$X1stFlrSF)
qqline(datos$X1stFlrSF, col='red')

plot(datos$X1stFlrSF, datos$SalePrice)
```

### GrLivArea

Los datos están ligeramente normalizados.
```{r}
hist(datos$GrLivArea)
qqnorm(datos$GrLivArea)
qqline(datos$GrLivArea, col='red')

plot(datos$GrLivArea, datos$SalePrice)
```

### GarageArea

Los datos están ligeramente normalizados.
```{r}
hist(datos$GarageArea)
qqnorm(datos$GarageArea)
qqline(datos$GarageArea, col='red')

plot(datos$GarageArea, datos$SalePrice)
```

### SalePrice

Los datos están ligeramente normalizados.
```{r}
hist(datos$SalePrice)
qqnorm(datos$SalePrice)
qqline(datos$SalePrice, col='red')
```

Se procede con ejecutar el algoritmo de clústeres (3) para generar grupos de BARATO, INTERMEDIO y CARO

```{r}
cluster <- datos
km <- kmeans(datos, 3)
datos$grupo <- km$cluster


g1<- datos[datos$grupo==1,]
g2<- datos[datos$grupo==2,]
g3<- datos[datos$grupo==3,]
```

Y, se cambia el nombre del grupo de número a palabras, para una mejor comprensión y un mejor análisis posterior.

```{r}
if ((min(g1$SalePrice) > min(g2$SalePrice)) && (min(g1$SalePrice) > min(g3$SalePrice))) {
  if (min(g2$SalePrice) > min(g3$SalePrice)) {
    a <- c("Caro", "Intermedio", "Bajo")
  } else {
    a <- c("Caro", "Bajo", "Intermedio")
  }
} else if ((min(g1$SalePrice) < min(g2$SalePrice)) && (min(g1$SalePrice) < min(g3$SalePrice))) {
  if (min(g2$SalePrice) < min(g3$SalePrice)) {
    a <- c("Bajo", "Intermedio", "Caro")
  } else {
    a <- c("Bajo", "Caro", "Intermedio")
  }
} else {
  if (min(g2$SalePrice) < min(g3$SalePrice)) {
    a <- c("Intermedio", "Bajo", "Caro")
  } else {
    a <- c("Intermedio", "Caro", "Bajo")
  }
}

datos$grupo <- mapvalues(datos$grupo, c(1, 2, 3), a)
```


Para el análisis y comparación de los algoritmos contra Regresión Logística, necesitamos que la variable respuesta (grupo) sea dicotómica, así que se procede a converter la variable categórica en dicotómica, y se parte el dataset en TRAIN y TEST para entrenamiento y cross validation.

```{r, message=FALSE, warning=FALSE}
porcentaje <- 0.7
datos <- cbind(datos, dummy(datos, verbose = T))
colnames(datos)[8:10] <- a

corte <- sample(nrow(datos), nrow(datos) * porcentaje)
train <- datos[corte, ]
test <- datos[-corte, ]

train$grupo <- as.factor(train$grupo)
test$grupo <- as.factor(test$grupo)
```

## Red Neuronal

### Con nnet (modelo 1)

Se utilizó una red neuronal con 5 capas ocultas, una cantidad máxima de iteraciones de 500 y una decadencia de los pesos de 5E-4.
```{r}
modelo <- nnet(grupo~., data = train[, c(1:5, 7)], size=5, rang=0.000001, decay=5e-4, maxit=500) 
prediccion2 <- as.data.frame(predict(modelo, newdata = test[, 1:5]))
columnaMasAlta <- apply(prediccion2, 1, function(x) colnames(prediccion2)[which.max(x)])
test$prediccion2 <- columnaMasAlta

confusionMatrix(as.factor(test$prediccion2), as.factor(test$grupo))
```

Vemos que este tipo de red neuronal obtiene un resultado de accuracy 82%. Aunque este valor es bastante bueno, si observamos la sensitividad de las casas caras, vemos que es de 0.65 aproximadamente, lo que nos indica que este modelo le es dificil predecir casas que son caras. Y, la especificidad y sensitividad de los otros es mayor a 0.8, y aunque están bien, no es el mejor escenario.

### Con WEKA (modelo 2)

El modelo de redes neuronales con WEKA, se utiliza una capa oculta con 5 nodos en ella, se utilizaron 5000 iteraciones para obtener un bajo costo de la función.
```{r}
NB <- make_Weka_classifier("weka/classifiers/functions/MultilayerPerceptron")
nnodos='5'

modeloWeka <- NB(grupo~., data=train[, c(1:5, 7)], control=Weka_control(H=nnodos, N=5000, G=TRUE), options=NULL)
test$prediccionWeka <- predict(modeloWeka, newdata = test[, 1:5])
confusionMatrix(test$prediccionWeka, test$grupo)
```

Los resultados son muy similares al modelo anterior. De igual forma, le cuesta predecir las caras que son caras, pues la sensitividad de las casas caras no alcanzó ni si quiera el 0.60. Se obtuvo un accuracy de 0.81. 

Podemos notar que, aunque los modelos de redes neuronales son buenos modelos, para este caso, es preferible utilizar otros modelos pues, aciertan más y son más precisos.

##SVM

##Modelo lineal 

```{r}
modeloTuneado<-tune.svm(grupo~., data=train[, c(1:5, 7)], cost=c(0.01,0.1,0.5,1,5,10,16,20,32), kernel="linear")
predMejorModelo<-predict(modeloTuneado$best.model,newdata = test[,1:5])
confusionMatrix(test$grupo,predMejorModelo)
```

En el caso del svm con modelo lineal se obtiene un resultado de accuracy 82.69%. Es bastante bueno. Si observamos la sensitividad , vemos que es mayor al 70 porciento en todas las categorias , por lo que cuentan con un indice estable para cada una de las categorías de las casas. 

En lo que respecta al tiempo de generación, le modelo se genero rápidamente. Tomando encuenta que la función tune utiliza realiza una mayor cantidad de iteraciones que si solo se hiciera un modelo , inica que el modelo se puede genrar de froma veloz. 

##Modelo Radial

```{r}
modeloTuneado<-tune.svm(grupo~., data=train[, c(1:5, 7)], cost=c(0.01,0.1,0.5,1,5,10,16,20,32), kernel="radial")
predMejorModelo<-predict(modeloTuneado$best.model,newdata = test[,1:5])
confusionMatrix(test$grupo,predMejorModelo)
```

En el caso del svm con modelo lineal se obtiene un resultado de accuracy 84.05%. Es bastante bueno, mejor que el modelo anterior. Si observamos la sensitividad sin embargo, vemos que disminuyo en la categoria de caro, aunque mejoro de gran manera en la categoria de casas bajas. 

En lo que respecta al tiempo de generación, le modelo se genero rápidamente. Tomando encuenta que la función tune utiliza realiza una mayor cantidad de iteraciones que si solo se hiciera un modelo , inica que el modelo se puede genrar de froma veloz. 


## Regresión Logística

```{r}
num <- which(colnames(train) == "Bajo")
modelo <- glm(Bajo~., data = train[, c(1:5, num)], family = binomial(), maxit = 100)

pred <- predict(modelo, newdata = test[, 1:5], type = "response")
prediccion <- ifelse(pred >= 0.5, 1, 0)
confusionMatrix(as.factor(test$Bajo), as.factor(prediccion))
```


Como vemos el resultado anterior, vemor que el modelo generado es muy bastante bueno. Predice correctamente 22 de 37, y 393 de 9. Posee un accuracy del 94.53%, con una sensitividad del 96.32% y especificidad del 70.97%, así que se concluye que el modelo de regresión logística para predecir si una cada es barata o no, es bueno, pues acierta casi en la totalidad, sin poseer overfitting.

Ahora, vemos un gráfica (de dos dimensiones) de la regresión logística.
```{r}
ggplot(data = test, aes(x = TotalBsmtSF, y = Bajo)) +
  geom_point(aes(color = as.factor(Bajo)), shape = 1) + 
  geom_smooth(method = "glm",
              method.args = list(family = "binomial"),
              color = "gray20",
              se = FALSE) +
  theme_bw() +
  theme(legend.position = "none")
```

## Naive Bayes

```{r}
nbTest = select(test, TotalBsmtSF, X1stFlrSF, GrLivArea, GarageCars, GarageArea, Bajo)
nbTrain = select(train, TotalBsmtSF, X1stFlrSF, GrLivArea, GarageCars, GarageArea, Bajo)

modelo <- naiveBayes(as.factor(nbTrain$Bajo)~., data=nbTrain)
predBayes <- predict(modelo, newdata = test[, 1:5])
confusionMatrix(as.factor(predBayes), as.factor(nbTest$Bajo))
```

Vemos que el modelo de Naive Bayes obtiene un accuracy del 91.57%. También, la sensitividad y la especificidad son relativamente altas: 0.9229 y 0.8379 respectivamente. Están bien, pero hay mejores modelos.
    
## Regresión Lineal

```{r}
lTest = select(test, TotalBsmtSF, X1stFlrSF, GrLivArea, GarageCars, GarageArea, Bajo)
lTrain = select(train, TotalBsmtSF, X1stFlrSF, GrLivArea, GarageCars, GarageArea, Bajo)

modelo <-lm (Bajo~., data = lTrain)

predMLM <-predict(modelo, newdata = lTest[1:5])
prediccion <- ifelse(predMLM >= 0.5, 1, 0)
confusionMatrix(as.factor(prediccion), as.factor(lTest$Bajo))
```

El resultado de la regresión lineal multiple es muy similar al de Naive Bayes, teniendo un accuracy del 0.9248. Con sensitividad y especificidad del 1 y 0.1081. Como se mencionó anteriormente, es buen resultado, pero hay mejores.


## Árbol de clasificación 

```{r}
ctTrain = select(train, TotalBsmtSF, X1stFlrSF, GrLivArea, GarageCars, GarageArea, Bajo)
ctTest = select(test, TotalBsmtSF, X1stFlrSF, GrLivArea, GarageCars, GarageArea, Bajo)
```

```{r}
dt_model<-rpart(ctTrain$Bajo~.,ctTrain,method = "class")
rpart.plot(dt_model)

prediccion <- predict(dt_model, newdata = ctTest[1:5])
columnaMasAlta<-apply(prediccion, 1, function(x) colnames(prediccion)[which.max(x)])
ctTest$prediccion<-columnaMasAlta #Se le añade al grupo de prueba el valor de la predicción

cfm<-table(ctTest$Bajo,ctTest$prediccion)
confusionMatrix(table(ctTest$prediccion, ctTest$Bajo))
cfm
```

El resultado del árbol de categorización es un accuracy del 0.9294. Con sensitividad y especificidad del 0.9627 y 0.5676. Como se mencionó anteriormente, es buen resultado, pero hay mejores.

## Árbol de regresión 

```{r}
rtTrain = select(train, TotalBsmtSF, X1stFlrSF, GrLivArea, GarageCars, GarageArea, SalePrice, Bajo)
rtTest = select(test, TotalBsmtSF, X1stFlrSF, GrLivArea, GarageCars, GarageArea, SalePrice, Bajo)
```

```{r}
dt_model<-rpart(rtTrain$SalePrice~.,rtTrain[1:6],method = "anova")
rpart.plot(dt_model)

prediccion <- predict(dt_model, newdata = rtTest[1:5])

rtTest$prediccion <- prediccion 
plot(rtTest$SalePrice, col='blue')
points(prediccion, col='green')
```

Gracias a que el árbol de regresión predice únicamente el precio de venta, y no la clase a la que pertenece se utilizaran los limites de precio la clase barata para determinar si la predicción de clase fue adecuada. 

```{r}
g<-datos[datos$Bajo==1,]
g<-datos[datos$datosIntermedio==1,]
```

Al observar el precio de venta máximo en la clase baja, se puede observar que es menor al mínimo precio de venta de la clase Intermedia. POr lo que las casas con un precio de venta mayor a 172000 son consideradas como clasificadas fuera de clase. +

```{r}
g1<-rtTest[rtTest$prediccion < 172000,]
g1$prediccionClase <- 1
g2<-rtTest[rtTest$prediccion >= 172000,]
g2$prediccionClase <- 0
rtTest <- bind_rows(g1,g2)
cfm<-table(rtTest$Bajo,rtTest$prediccionClase)
confusionMatrix(table(rtTest$prediccionClase, rtTest$Bajo))
```
El resultado del árbol de regresión es bastante deficiente. Se optuvo un rendimiento del 36%. Tomando en cuenta que este algoritmo no esta diseñado para la predicción de clases, se entiende la razón del mismo. 

# Resultado

En resumen, se realizó una tabla que muestra los accuracy de cada modelo. Y podemos ver que para este análisis, la regresión logística de desempeñó de mejor manera que los demás modelos, con un 94% de presición. 

En el caso de los modelos analizados en específico para este ejercicio, podemos observar que ambos se desempeñan de manera similar en lo que respecta a porcentajes de presición, alrededor del 80%. Sin embargo las redes neuronales toman más tiempo en generarse, lo que podría llegar a ser una desventaja. 

```{r}
resultado <- data.frame("Regresion_Logistica" = 0.9453, "Naive_Bayes" = 0.9157, "Regresion_lineal" = 0.9248, "Arbol_de_clasificacion" = 0.9294, "Arbol_de_regresion" = 0.3599, "Redes N. con nnet" = 0.82, "Redes N. con WEKA" = 0.81, "SVM lineal" = 0.83, "SVM radial" = 0.84)
kable(resultado, caption = "Accuracy por modelo")
```
