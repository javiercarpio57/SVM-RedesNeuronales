---
title: "Modelo de Support Vector Machin & Redes neuronales"
author: "Javier Carpio & Paul Belches"
date: "13/04/2020"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r, include=FALSE}
library(caret)
library(dummies)
```

Para empezar con el análisis de los siguientes algoritmos: 

    * Árboles de decisión
    * Random Forest
    * Naive Bayes
    * Regresión Lineal
    * Regresión Logística
  
Debemos cargar el dataset llamado "train.csv", y para este dataset se tomarán las siguientes variables:

    * TotalBsmtSF
    * X1stFlrSF
    * GrLivArea
    * GarageCars
    * GarageArea
    * SalePrice
  
Pues como se ve en el gráfico de correlación podemos ver que tienen alta correlación con el SalePrice, que es la variable respuesta para este análisis. 
```{r}
houses <- read.csv("train.csv")
set.seed(123)

datos <-select(houses, TotalBsmtSF, X1stFlrSF, GrLivArea, GarageCars, GarageArea, SalePrice)
datos <- na.omit(datos)
matriz_cor <- cor(datos)
corrplot(matriz_cor)
```

### TotalBsmtSF

Los datos están ligeramente normalizados.
```{r}
hist(datos$TotalBsmtSF)
qqnorm(datos$TotalBsmtSF)
qqline(datos$TotalBsmtSF, col='red')

plot(datos$TotalBsmtSF, datos$SalePrice)
```

### X1stFlrSF

Los datos están ligeramente normalizados.
```{r}
hist(datos$X1stFlrSF)
qqnorm(datos$X1stFlrSF)
qqline(datos$X1stFlrSF, col='red')

plot(datos$X1stFlrSF, datos$SalePrice)
```

### GrLivArea

Los datos están ligeramente normalizados.
```{r}
hist(datos$GrLivArea)
qqnorm(datos$GrLivArea)
qqline(datos$GrLivArea, col='red')

plot(datos$GrLivArea, datos$SalePrice)
```

### GarageArea

Los datos están ligeramente normalizados.
```{r}
hist(datos$GarageArea)
qqnorm(datos$GarageArea)
qqline(datos$GarageArea, col='red')

plot(datos$GarageArea, datos$SalePrice)
```

### SalePrice

Los datos están ligeramente normalizados.
```{r}
hist(datos$SalePrice)
qqnorm(datos$SalePrice)
qqline(datos$SalePrice, col='red')
```

Se procede con ejecutar el algoritmo de clústeres (3) para generar grupos de BARATO, INTERMEDIO y CARO

```{r}
cluster <- datos
km <- kmeans(datos, 3)
datos$grupo <- km$cluster


g1<- datos[datos$grupo==1,]
g2<- datos[datos$grupo==2,]
g3<- datos[datos$grupo==3,]
```

Y, se cambia el nombre del grupo de número a palabras, para una mejor comprensión y un mejor análisis posterior.

```{r}
if ((min(g1$SalePrice) > min(g2$SalePrice)) && (min(g1$SalePrice) > min(g3$SalePrice))) {
  if (min(g2$SalePrice) > min(g3$SalePrice)) {
    a <- c("Caro", "Intermedio", "Bajo")
  } else {
    a <- c("Caro", "Bajo", "Intermedio")
  }
} else if ((min(g1$SalePrice) < min(g2$SalePrice)) && (min(g1$SalePrice) < min(g3$SalePrice))) {
  if (min(g2$SalePrice) < min(g3$SalePrice)) {
    a <- c("Bajo", "Intermedio", "Caro")
  } else {
    a <- c("Bajo", "Caro", "Intermedio")
  }
} else {
  if (min(g2$SalePrice) < min(g3$SalePrice)) {
    a <- c("Intermedio", "Bajo", "Caro")
  } else {
    a <- c("Intermedio", "Caro", "Bajo")
  }
}

datos$grupo <- mapvalues(datos$grupo, c(1, 2, 3), a)
```

Para el análisis y comparación de los algoritmos contra Regresión Logística, necesitamos que la variable respuesta (grupo) sea dicotómica, así que se procede a converter la variable categórica en dicotómica, y se parte el dataset en TRAIN y TEST para entrenamiento y cross validation.

```{r, message=FALSE, warning=FALSE}
porcentaje <- 0.7
datos <- cbind(datos, dummy(datos$grupo, verbose = T))
colnames(datos)[8:10] <- a

corte <- sample(nrow(datos), nrow(datos) * porcentaje)
train <- datos[corte, ]
test <- datos[-corte, ]
```

## Regresión Logística
    
### Training
```{r}
num <- which(colnames(train) == "Bajo")
modelo <- glm(Bajo~., data = train[, c(1:5, num)], family = binomial(), maxit = 100)

modelo

summary(modelo)
```

Vemos que todas las variables poseen un nivel de significancia alto, a excepción de X1stFlrSF, pero se dejará en el modelo pues tiene buena correlación con SalePrice.

### Testing
```{r}
pred <- predict(modelo, newdata = test[, 1:5], type = "response")
prediccion <- ifelse(pred >= 0.5, 1, 0)
confusionMatrix(as.factor(test$Bajo), as.factor(prediccion))
```

Como vemos el resultado anterior, vemor que el modelo generado es muy bastante bueno. Predice correctamente 22 de 37, y 393 de 9. Posee un accuracy del 94.53%, con una sensitividad del 96.32% y especificidad del 70.97%, así que se concluye que el modelo de regresión logística para predecir si una cada es barata o no, es bueno, pues acierta casi en la totalidad, sin poseer overfitting.

Ahora, vemos un gráfica (de dos dimensiones) de la regresión logística.
```{r}
ggplot(data = test, aes(x = TotalBsmtSF, y = Bajo)) +
  geom_point(aes(color = as.factor(Bajo)), shape = 1) + 
  geom_smooth(method = "glm",
              method.args = list(family = "binomial"),
              color = "gray20",
              se = FALSE) +
  theme_bw() +
  theme(legend.position = "none")
```

## Naive Bayes

```{r}
nbTest = select(test, TotalBsmtSF, X1stFlrSF, GrLivArea, GarageCars, GarageArea, Bajo)
nbTrain = select(train, TotalBsmtSF, X1stFlrSF, GrLivArea, GarageCars, GarageArea, Bajo)

modelo <- naiveBayes(as.factor(nbTrain$Bajo)~., data=nbTrain)
predBayes <- predict(modelo, newdata = test[, 1:5])
confusionMatrix(as.factor(predBayes), as.factor(nbTest$Bajo))
```

Vemos que el modelo de Naive Bayes obtiene un accuracy del 91.57%. También, la sensitividad y la especificidad son relativamente altas: 0.9229 y 0.8379 respectivamente. Están bien, pero hay mejores modelos.
    
## Regresión Lineal

```{r}
lTest = select(test, TotalBsmtSF, X1stFlrSF, GrLivArea, GarageCars, GarageArea, Bajo)
lTrain = select(train, TotalBsmtSF, X1stFlrSF, GrLivArea, GarageCars, GarageArea, Bajo)

modelo <-lm (Bajo~., data = lTrain)

predMLM <-predict(modelo, newdata = lTest[1:5])
prediccion <- ifelse(predMLM >= 0.5, 1, 0)
confusionMatrix(as.factor(prediccion), as.factor(lTest$Bajo))
```

El resultado de la regresión lineal multiple es muy similar al de Naive Bayes, teniendo un accuracy del 0.9248. Con sensitividad y especificidad del 1 y 0.1081. Como se mencionó anteriormente, es buen resultado, pero hay mejores.


## Árbol de clasificación 

```{r}
ctTrain = select(train, TotalBsmtSF, X1stFlrSF, GrLivArea, GarageCars, GarageArea, Bajo)
ctTest = select(test, TotalBsmtSF, X1stFlrSF, GrLivArea, GarageCars, GarageArea, Bajo)
```

```{r}
dt_model<-rpart(ctTrain$Bajo~.,ctTrain,method = "class")
rpart.plot(dt_model)

prediccion <- predict(dt_model, newdata = ctTest[1:5])
columnaMasAlta<-apply(prediccion, 1, function(x) colnames(prediccion)[which.max(x)])
ctTest$prediccion<-columnaMasAlta #Se le añade al grupo de prueba el valor de la predicción

cfm<-table(ctTest$Bajo,ctTest$prediccion)
confusionMatrix(table(ctTest$prediccion, ctTest$Bajo))
cfm
```

El resultado del árbol de categorización es un accuracy del 0.9294. Con sensitividad y especificidad del 0.9627 y 0.5676. Como se mencionó anteriormente, es buen resultado, pero hay mejores.

## Árbol de regresión 

```{r}
rtTrain = select(train, TotalBsmtSF, X1stFlrSF, GrLivArea, GarageCars, GarageArea, SalePrice, Bajo)
rtTest = select(test, TotalBsmtSF, X1stFlrSF, GrLivArea, GarageCars, GarageArea, SalePrice, Bajo)
```

```{r}
dt_model<-rpart(rtTrain$SalePrice~.,rtTrain[1:6],method = "anova")
rpart.plot(dt_model)

prediccion <- predict(dt_model, newdata = rtTest[1:5])

rtTest$prediccion <- prediccion 
plot(rtTest$SalePrice, col='blue')
points(prediccion, col='green')
```

Gracias a que el árbol de regresión predice únicamente el precio de venta, y no la clase a la que pertenece se utilizaran los limites de precio la clase barata para determinar si la predicción de clase fue adecuada. 

```{r}
g<-datos[datos$Bajo==1,]
g<-datos[datos$datosIntermedio==1,]
```

Al observar el precio de venta máximo en la clase baja, se puede observar que es menor al mínimo precio de venta de la clase Intermedia. POr lo que las casas con un precio de venta mayor a 172000 son consideradas como clasificadas fuera de clase. +

```{r}
g1<-rtTest[rtTest$prediccion < 172000,]
g1$prediccionClase <- 1
g2<-rtTest[rtTest$prediccion >= 172000,]
g2$prediccionClase <- 0
rtTest <- bind_rows(g1,g2)
cfm<-table(rtTest$Bajo,rtTest$prediccionClase)
confusionMatrix(table(rtTest$prediccionClase, rtTest$Bajo))
```
El resultado del árbol de regresión es bastante deficiente. Se optuvo un rendimiento del 36%. Tomando en cuenta que este algoritmo no esta diseñado para la predicción de clases, se entiende la razón del mismo. 

# Resultado

En resumen, se realizó una tabla que muestra los accuracy de cada modelo. Y podemos ver que para este análisis, la regresión logística de desempeñó de mejor manera que los demás modelos, con un 94% de presición. Esto 

```{r}
resultado <- data.frame("Regresion_Logistica" = 0.9453, "Naive_Bayes" = 0.9157, "Regresion_lineal" = 0.9248, "Arbol_de_clasificacion" = 0.9294, "Arbol_de_regresion" = 0.3599)
kable(resultado, caption = "Accuracy por modelo")
```
